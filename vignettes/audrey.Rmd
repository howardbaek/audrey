---
title: "Introduction to audrey"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to audrey}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

This vignette introduces you to audrey's functions for automatic speech recognition (ASR) with OpenAI's [Whisper](https://openai.com/research/whisper). Whisper is an automatic speech recognition (ASR) system trained on 680,000 hours of multilingual and multitask supervised data collected from the web. When the OpenAI developers measured Whisperâ€™s zero-shot performance across many diverse datasets, they found it is much more robust and makes 50% fewer errors than other models.

## Setup

To utilize this system, you must download Whisper and ffmpeg on your system. 

```{bash}
# Install Whisper
pip install -U openai-whisper

# Install ffmpeg
# on Ubuntu or Debian
sudo apt update && sudo apt install ffmpeg

# on Arch Linux
sudo pacman -S ffmpeg

# on MacOS using Homebrew (https://brew.sh/)
brew install ffmpeg

# on Windows using Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# on Windows using Scoop (https://scoop.sh/)
scoop install ffmpeg
```

Refer to Whisper's [Setup](https://github.com/openai/whisper#setup) documentation for more information.

## Speech Recognition

```{r setup}
library(audrey)
```

`transcribe()` performs speech recognition by converting spoken language from the input audio file into written text in its original language. 

For example, let's say we provide the following audio file as input:

<audio controls>
    <source src="audio/sample1.mp3" type="audio/mp3"/>
</audio>

Then, we transcribe this audio file:

```{r}
transcribe("audio/sample1.mp3", output_dir = ".")
```

Once the function successfully runs, it will return the written text as well as a success message and the location where the output txt file has been stored. 


## Translate Speech into English

`translate()` converts non-English audio into English. It is recommended to provide the language spoken in the audio as the `audio_lang` argument to `translate()`. 

For example, let's say we provide the following Korean audio file as input:

<audio controls>
    <source src="audio/sample2.mp3" type="audio/mp3"/>
</audio>

Then, we translate this audio file:

```{r}
translate("audio/sample2.mp3", audio_lang = "Korean", output_dir = ".")
```

Similar to `transcribe()`, once the function runs, it will return the written English text as well as a success message and the location where the output txt file has been stored. 


